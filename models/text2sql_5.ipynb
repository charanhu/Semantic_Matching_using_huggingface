{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text to sql\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"tscholak/3vnuv1vf\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"tscholak/3vnuv1vf\")\n",
    "\n",
    "# Tokenize the input text\n",
    "input_text = \"list names of film released in 2018 and rating more than 6? | IMDB | Movie: rating, year, title\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate the output\n",
    "output = model.generate(input_ids, max_length=128, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Decode the output\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output_text)\n",
    "# Output: IMDB | select title from movie where rating > 6 and year = 2018\n",
    "\n",
    "# split the output into two parts (sql and table name)\n",
    "output_text = output_text.split(\"|\")\n",
    "sql = output_text[1].strip()\n",
    "\n",
    "# print the sql\n",
    "print(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import sqlite3\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    # First element of model_output contains all token embeddings\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(\n",
    "        -1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Query sentence\n",
    "query_sentence = input(\"Enter question: \")\n",
    "\n",
    "# Connect to database and fetch table names and column names\n",
    "conn = sqlite3.connect('/content/Db-IMDB.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "# Get table names\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "table_names = cursor.fetchall()\n",
    "table_names = [x[0] for x in table_names]\n",
    "\n",
    "# generate string in this format: query_sentence | database_name | table_name1: column_name1(value1, value2, value3, ...), column_name2(value1, value2, value3, ...), ... | table_name2: column_name1(value1, value2, value3, ...), column_name2(value1, value2, value3, ...), ... | ...\n",
    "input_text = query_sentence + \" | IMDB | \"\n",
    "for table_name in table_names:\n",
    "    input_text += table_name + \": \"\n",
    "    cursor.execute(\"PRAGMA table_info(\" + table_name + \")\")\n",
    "    column_names = cursor.fetchall()\n",
    "    column_names = [x[1] for x in column_names]\n",
    "    for column_name in column_names:\n",
    "        cursor.execute(\"SELECT DISTINCT \" + column_name + \" FROM \" + table_name)\n",
    "        values = cursor.fetchall()\n",
    "        values = [x[0] for x in values]\n",
    "        input_text += column_name + \"(\"\n",
    "        for value in values:\n",
    "            input_text += str(value) + \", \"\n",
    "        input_text = input_text[:-2]\n",
    "        input_text += \"), \"\n",
    "    input_text = input_text[:-2]\n",
    "    input_text += \" | \"\n",
    "\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python code to generate a string in this format [question] | [db_id] | [table] : [column] ( [content] , [content] ) , [column] ( ... ) , [...] | [table] : ... | ...\n",
    "\n",
    "def get_sql(query):\n",
    "    # Tokenize the input text\n",
    "    input_ids = tokenizer.encode(query, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate the output\n",
    "    output = model.generate(input_ids, max_length=128, num_beams=4, early_stopping=True)\n",
    "\n",
    "    # Decode the output\n",
    "    output_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(output_text)\n",
    "    # Output: IMDB | select title from movie where rating > 6 and year = 2018\n",
    "\n",
    "    # split the output into two parts (sql and table name)\n",
    "    output_text = output_text.split(\"|\")\n",
    "    sql = output_text[1].strip()\n",
    "\n",
    "    # print the sql\n",
    "    print(sql)\n",
    "    return sql"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1f682f24181e02bec5294285fb1c175cb07785bd2390f987c80770a76d37385"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
