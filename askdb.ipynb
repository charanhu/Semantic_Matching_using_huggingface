{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load the database and create a connection\n",
    "conn = sqlite3.connect(\"/content/Db-IMDB.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get all tables in the database\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "\n",
    "# Store the table names and column names in a dictionary, whree the key is the table name and the value is a list of column names\n",
    "table_dict = {}\n",
    "for table in tables:\n",
    "    cursor.execute(\"PRAGMA table_info({})\".format(table[0]))\n",
    "    table_dict[table[0]] = [column[1] for column in cursor.fetchall()]\n",
    "\n",
    "# Print the table names and column names\n",
    "for table in table_dict:\n",
    "    print(table)\n",
    "    print(table_dict[table])\n",
    "\n",
    "# Get English Question from user\n",
    "question = input(\"Enter your question: \")\n",
    "\n",
    "# Tokenize the question\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenized_question = tokenizer.tokenize(question)\n",
    "\n",
    "# Semantic search for the question to find the semantically matching table names and column names of the database\n",
    "# The semantic search is done using the BERT model\n",
    "def semantic_search(question, table_dict):\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    model.eval()\n",
    "    question_embedding = model(tokenizer(question, return_tensors=\"pt\")[\"input_ids\"])[0]\n",
    "    table_dict_embeddings = {}\n",
    "    for table in table_dict:\n",
    "        table_dict_embeddings[table] = model(tokenizer(\" \".join(table_dict[table]), return_tensors=\"pt\")[\"input_ids\"])[0]\n",
    "    table_dict_scores = {}\n",
    "    for table in table_dict_embeddings:\n",
    "        table_dict_scores[table] = model.cosine_similarity(question_embedding, table_dict_embeddings[table])\n",
    "    return table_dict_scores\n",
    "\n",
    "# Get the table name and column name with the highest score\n",
    "def get_best_match(table_dict_scores):\n",
    "    best_match = max(table_dict_scores, key=table_dict_scores.get)\n",
    "    best_match_score = table_dict_scores[best_match]\n",
    "    return best_match, best_match_score\n",
    "\n",
    "# Print the table name and column name with the highest score\n",
    "table_dict_scores = semantic_search(question, table_dict)\n",
    "best_match, best_match_score = get_best_match(table_dict_scores)\n",
    "print(\"Best match: \", best_match)\n",
    "print(\"Best match score: \", best_match_score)\n",
    "\n",
    "\n",
    "# close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT model and tokenizer\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Preprocess the English question\n",
    "question = \"List all movies where ?\"\n",
    "input_ids = torch.tensor(tokenizer.encode(\n",
    "    question)).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "# Generate a semantic representation of the question\n",
    "output = model(input_ids)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Query sentence\n",
    "query_sentence = 'what are the names of movies?'\n",
    "\n",
    "# Connect to database and fetch table names and column names\n",
    "conn = sqlite3.connect('/content/Db-IMDB.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "table_names = [table_info[0] for table_info in cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()]\n",
    "column_names = []\n",
    "for table_name in table_names:\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    column_names.extend([column_info[1] for column_info in cursor.fetchall()])\n",
    "\n",
    "# Tokenize query sentence, table names, and column names\n",
    "query_sentence_encoded = tokenizer([query_sentence], padding=True, truncation=True, return_tensors='pt')\n",
    "table_names_encoded = tokenizer(table_names, padding=True, truncation=True, return_tensors='pt')\n",
    "column_names_encoded = tokenizer(column_names, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings for query sentence, table names, and column names\n",
    "with torch.no_grad():\n",
    "    query_sentence_output = model(**query_sentence_encoded)\n",
    "    table_names_output = model(**table_names_encoded)\n",
    "    column_names_output = model(**column_names_encoded)\n",
    "\n",
    "# Perform pooling for query sentence, table names, and column names\n",
    "query_sentence_embedding = mean_pooling(query_sentence_output, query_sentence_encoded['attention_mask'])\n",
    "table_names_embeddings = mean_pooling(table_names_output, table_names_encoded['attention_mask'])\n",
    "column_names_embeddings = mean_pooling(column_names_output, column_names_encoded['attention_mask'])\n",
    "\n",
    "# Normalize embeddings for query sentence, table names, and column names\n",
    "query_sentence_embedding = F.normalize(query_sentence_embedding, p=2, dim=1)\n",
    "table_names_embeddings = F.normalize(table_names_embeddings, p=2, dim=1)\n",
    "column_names_embeddings = F.normalize(column_names_embeddings, p=2, dim=1)\n",
    "\n",
    "# Find the most similar table names and column names by computing the cosine similarity between the query sentence embedding and the table names and column names embeddings\n",
    "cosine_similarities_tables = torch.nn.functional.cosine_similarity(query_sentence_embedding, table_names_embeddings, dim=1)\n",
    "most_similar_table_names_indices = cosine_similarities_tables.argsort(descending=True)\n",
    "most_similar_table_names = [table_names[i] for i in most_similar_table_names_indices]\n",
    "\n",
    "cosine_similarities_columns = torch.nn.functional.cosine_similarity(query_sentence_embedding, column_names_embeddings, dim=1)\n",
    "most_similar_column_names_indices = cosine_similarities_columns.argsort(descending=True)\n",
    "most_similar_column_names = [column_names[i] for i in most_similar_column_names_indices]\n",
    "\n",
    "print(f\"Most similar table names to '{query_sentence}': {most_similar_table_names}\")\n",
    "print(f\"Most similar column names to '{query_sentence}': {most_similar_column_names}\")\n",
    "\n",
    "# Print the most similar table names with there cosine similarity scores in descending order\n",
    "for i in range(len(most_similar_table_names)):\n",
    "    print(f\"Table name: {most_similar_table_names[i]}, cosine similarity score: {cosine_similarities_tables[most_similar_table_names_indices[i]]}\")\n",
    "\n",
    "# Print the highest cosine similarity score table name, and print the highest cosine similarity score column name of the highest cosine similarity score table name\n",
    "print(f\"Table name with highest cosine similarity score: {most_similar_table_names[0]}\")\n",
    "print(f\"Column name with highest cosine similarity score: {most_similar_column_names[0]}\")\n",
    "\n",
    "\n",
    "\n",
    "# Close database connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8dfc8609dd5180df3f92c99aa3a5777dcce9aad48aad7f045d6c2f519bdbe44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
