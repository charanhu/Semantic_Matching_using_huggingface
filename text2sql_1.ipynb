{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    # First element of model_output contains all token embeddings\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(\n",
    "        -1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Query sentence\n",
    "query_sentence = 'what are the names of films?'\n",
    "\n",
    "# Connect to database and fetch table names and column names\n",
    "conn = sqlite3.connect('/content/Db-IMDB.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get the filename that is connected above\n",
    "filename = conn.cursor().execute(\"PRAGMA database_list;\").fetchall()[0][2]\n",
    "\n",
    "# filename = '/content/Db-IMDB.db'\n",
    "# split the filename to get the database name\n",
    "database_name = filename.split('/')[-1].split('.')[0]\n",
    "\n",
    "table_names = [table_info[0] for table_info in cursor.execute(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()]\n",
    "column_names = []\n",
    "for table_name in table_names:\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    column_names.extend([column_info[1] for column_info in cursor.fetchall()])\n",
    "\n",
    "# Tokenize query sentence, table names\n",
    "query_sentence_encoded = tokenizer(\n",
    "    [query_sentence], padding=True, truncation=True, return_tensors='pt')\n",
    "table_names_encoded = tokenizer(\n",
    "    table_names, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings for query sentence, table names\n",
    "with torch.no_grad():\n",
    "    query_sentence_output = model(**query_sentence_encoded)\n",
    "    table_names_output = model(**table_names_encoded)\n",
    "\n",
    "# Perform pooling for query sentence, table names\n",
    "query_sentence_embedding = mean_pooling(\n",
    "    query_sentence_output, query_sentence_encoded['attention_mask'])\n",
    "table_names_embeddings = mean_pooling(\n",
    "    table_names_output, table_names_encoded['attention_mask'])\n",
    "\n",
    "# Normalize embeddings for query sentence, table names\n",
    "query_sentence_embedding = F.normalize(query_sentence_embedding, p=2, dim=1)\n",
    "table_names_embeddings = F.normalize(table_names_embeddings, p=2, dim=1)\n",
    "\n",
    "# Find the most similar table names by computing the cosine similarity between the query sentence embedding and the table names embeddings\n",
    "cosine_similarities_tables = torch.nn.functional.cosine_similarity(\n",
    "    query_sentence_embedding, table_names_embeddings, dim=1)\n",
    "most_similar_table_names_indices = cosine_similarities_tables.argsort(\n",
    "    descending=True)\n",
    "most_similar_table_names = [table_names[i]\n",
    "                            for i in most_similar_table_names_indices]\n",
    "\n",
    "# Print the most similar table names with there cosine similarity scores in descending order\n",
    "for i in range(len(most_similar_table_names)):\n",
    "    print(\n",
    "        f\"Table name: {most_similar_table_names[i]}, cosine similarity score: {cosine_similarities_tables[most_similar_table_names_indices[i]]}\")\n",
    "\n",
    "# Find the index of the highest matching table name by finding the maximum value in the list of cosine similarities for the table names\n",
    "max_similarity_table_index = cosine_similarities_tables.argmax()\n",
    "\n",
    "# Get the highest matching table name by using the index obtained above\n",
    "highest_matching_table_name = table_names[max_similarity_table_index]\n",
    "\n",
    "# Find the column names of the highest matching table by querying the database\n",
    "cursor.execute(f\"PRAGMA table_info({highest_matching_table_name});\")\n",
    "highest_matching_table_column_names = [\n",
    "    column_info[1] for column_info in cursor.fetchall()]\n",
    "\n",
    "# Tokenize the column names of the highest matching table\n",
    "highest_matching_table_column_names_encoded = tokenizer(\n",
    "    highest_matching_table_column_names, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute the token embeddings for the column names of the highest matching table\n",
    "with torch.no_grad():\n",
    "    highest_matching_table_column_names_output = model(\n",
    "        **highest_matching_table_column_names_encoded)\n",
    "\n",
    "# Perform mean pooling on the output of the language model for the column names of the highest matching table\n",
    "highest_matching_table_column_names_embeddings = mean_pooling(\n",
    "    highest_matching_table_column_names_output, highest_matching_table_column_names_encoded['attention_mask'])\n",
    "\n",
    "# Normalize the embeddings for the column names of the highest matching table\n",
    "highest_matching_table_column_names_embeddings = F.normalize(\n",
    "    highest_matching_table_column_names_embeddings, p=2, dim=1)\n",
    "\n",
    "# Compute the cosine similarity between the query sentence embedding and the column names embeddings of the highest matching table\n",
    "cosine_similarities_highest_matching_table_columns = torch.nn.functional.cosine_similarity(\n",
    "    query_sentence_embedding, highest_matching_table_column_names_embeddings, dim=1)\n",
    "\n",
    "# Find the most similar column name in the highest matching table by sorting the cosine similarities in descending order\n",
    "most_similar_highest_matching_table_column_name_index = cosine_similarities_highest_matching_table_columns.argmax()\n",
    "most_similar_highest_matching_table_column_name = highest_matching_table_column_names[\n",
    "    most_similar_highest_matching_table_column_name_index]\n",
    "\n",
    "# Print the most similar column name in the highest matching table\n",
    "print(\"----------------------------------\")\n",
    "print(\n",
    "    f\"Most similar column name in the highest matching table ({highest_matching_table_name}): {most_similar_highest_matching_table_column_name}\")\n",
    "\n",
    "\n",
    "highest_matching_table_column_names = \", \".join(highest_matching_table_column_names)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer_1 = AutoTokenizer.from_pretrained(\"tscholak/3vnuv1vf\")\n",
    "model_1 = AutoModelForSeq2SeqLM.from_pretrained(\"tscholak/3vnuv1vf\")\n",
    "\n",
    "# Make input text in this format. input_text = \"list names of film released in 2018 and rating more than 6? | IMDB | Movie: rating, year, title\"\n",
    "input_text_1 = query_sentence + \" | \" + database_name + \" | \" + highest_matching_table_name + \": \" + highest_matching_table_column_names\n",
    "\n",
    "input_ids_1 = tokenizer_1.encode(input_text_1, return_tensors=\"pt\")\n",
    "\n",
    "# Generate the output\n",
    "output_1 = model_1.generate(input_ids_1, max_length=128, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Decode the output\n",
    "output_text_1 = tokenizer_1.decode(output_1[0], skip_special_tokens=True)\n",
    "print(output_text_1)\n",
    "# Output: IMDB | select title from movie where rating > 6 and year = 2018\n",
    "\n",
    "# split the output into two parts (sql and table name)\n",
    "output_text_1 = output_text_1.split(\"|\")\n",
    "sql_1 = output_text_1[1].strip()\n",
    "\n",
    "# print the sql\n",
    "print(sql_1)\n",
    "\n",
    "# Execute the sql\n",
    "cursor.execute(sql_1)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "# print the result\n",
    "print(result)\n",
    "\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple,banana,cherry\n"
     ]
    }
   ],
   "source": [
    "list =[\"apple\",\"banana\",\"cherry\"]\n",
    "\n",
    "# convert the list to a string seapaerated by comma\n",
    "list_string = \",\".join(list)\n",
    "\n",
    "print(list_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select title_name from movie where ship_mode = 2018\n",
      " select \"title_name\" from movie where \"ship_mode\" = 2018\n",
      " select \"title name\" from movie where \"ship mode\" = 2018\n"
     ]
    }
   ],
   "source": [
    "s1 = \"select title_name from movie where ship_mode = 2018\"\n",
    "print(str(s1))\n",
    "s1 = s1.split()\n",
    "list = [\"title_name\", \"ship_mode\", \"rating\"]\n",
    "\n",
    "s2 = \"\"\n",
    "\n",
    "for i in s1:\n",
    "    if i in list:\n",
    "        # write it in duble quotes\n",
    "        s2 = s2 +\" \"+ '\"' + i + '\"'\n",
    "    else:\n",
    "        s2 = s2 +\" \"+ i\n",
    "\n",
    "print(s2)\n",
    "\n",
    "# remove underscore from the string\n",
    "s2 = s2.replace(\"_\", \" \")\n",
    "\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select title_name from movie where ship_mode = 2018\n",
      " select \"title_name\" from movie where \"ship_mode\" = 2018\n",
      " select \"title name\" from movie where \"ship mode\" = 2018\n"
     ]
    }
   ],
   "source": [
    "s1 = \"select title_name from movie where ship_mode = 2018\"\n",
    "print(s1)\n",
    "s1 = s1.split()\n",
    "list = [\"title_name\", \"ship_mode\", \"rating\"]\n",
    "\n",
    "s2 = \"\"\n",
    "\n",
    "for i in s1:\n",
    "    if i in list:\n",
    "        # write it in duble quotes\n",
    "        s2 = s2 +\" \"+ '\"' + i + '\"'\n",
    "    else:\n",
    "        s2 = s2 +\" \"+ i\n",
    "\n",
    "print(s2)\n",
    "\n",
    "# remove underscore from the string\n",
    "s2 = s2.replace(\"_\", \" \")\n",
    "\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sales', 'ship_mode']\n",
      "select \"sales\", \"ship mode\" from train where \"ship mode\"\n"
     ]
    }
   ],
   "source": [
    "s3  = \"select sales, ship_mode from train where ship_mode\"\n",
    "\n",
    "lst1 = [\"Sales\", \"ship_mode\"]\n",
    "\n",
    "# convert list to lower case\n",
    "lst1 = [x.lower() for x in lst1]\n",
    "print(lst1)\n",
    "\n",
    "# if s3 contains any of the words in lst1 then replace it with double quotes\n",
    "for i in lst1:\n",
    "    if i in s3:\n",
    "        s3 = s3.replace(i, '\"'+i+'\"')\n",
    "        # replace underscore with space\n",
    "\n",
    "# replace underscore with space\n",
    "s3 = s3.replace(\"_\", \" \")\n",
    "\n",
    "\n",
    "\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8dfc8609dd5180df3f92c99aa3a5777dcce9aad48aad7f045d6c2f519bdbe44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
