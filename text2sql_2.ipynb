{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    # First element of model_output contains all token embeddings\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(\n",
    "        -1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Define the English question\n",
    "query_sentence = 'What are names of films?'\n",
    "\n",
    "# Connect to database and fetch table names and column names\n",
    "# Update the path to the database file\n",
    "conn = sqlite3.connect('/content/Db-IMDB.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "table_names = [table_info[0] for table_info in cursor.execute(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()]\n",
    "column_names = []\n",
    "for table_name in table_names:\n",
    "    cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "    column_names.extend([column_info[1] for column_info in cursor.fetchall()])\n",
    "\n",
    "# Tokenize query sentence, table names, and column names\n",
    "query_sentence_encoded = tokenizer(\n",
    "    [query_sentence], padding=True, truncation=True, return_tensors='pt')\n",
    "table_names_encoded = tokenizer(\n",
    "    table_names, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings for query sentence, table names, and column names\n",
    "with torch.no_grad():\n",
    "    query_sentence_output = model(**query_sentence_encoded)\n",
    "    table_names_output = model(**table_names_encoded)\n",
    "\n",
    "# Perform pooling for query sentence, table names, and column names\n",
    "query_sentence_embedding = mean_pooling(\n",
    "    query_sentence_output, query_sentence_encoded['attention_mask'])\n",
    "table_names_embeddings = mean_pooling(\n",
    "    table_names_output, table_names_encoded['attention_mask'])\n",
    "\n",
    "# Normalize embeddings for query sentence, table names, and column names\n",
    "query_sentence_embedding = F.normalize(query_sentence_embedding, p=2, dim=1)\n",
    "table_names_embeddings = F.normalize(table_names_embeddings, p=2, dim=1)\n",
    "\n",
    "# Find the most similar table names and column names by computing the cosine similarity between the query sentence embedding and the table names and column names embeddings\n",
    "cosine_similarities_tables = torch.nn.functional.cosine_similarity(\n",
    "    query_sentence_embedding, table_names_embeddings, dim=1)\n",
    "most_similar_table_names_indices = cosine_similarities_tables.argsort(\n",
    "    descending=True)\n",
    "most_similar_table_names = [table_names[i]\n",
    "                            for i in most_similar_table_names_indices]\n",
    "\n",
    "# Print the most similar table names with there cosine similarity scores in descending order\n",
    "for i in range(len(most_similar_table_names)):\n",
    "    print(\n",
    "        f\"Table name: {most_similar_table_names[i]}, cosine similarity score: {cosine_similarities_tables[most_similar_table_names_indices[i]]}\")\n",
    "\n",
    "# Find the index of the highest matching table name by finding the maximum value in the list of cosine similarities for the table names\n",
    "max_similarity_table_index = cosine_similarities_tables.argmax()\n",
    "\n",
    "# Get the highest matching table name by using the index obtained above\n",
    "highest_matching_table_name = table_names[max_similarity_table_index]\n",
    "\n",
    "# Find the column names of the highest matching table by querying the database\n",
    "cursor.execute(f\"PRAGMA table_info({highest_matching_table_name});\")\n",
    "highest_matching_table_column_names = [\n",
    "    column_info[1] for column_info in cursor.fetchall()]\n",
    "\n",
    "# Tokenize the column names of the highest matching table\n",
    "highest_matching_table_column_names_encoded = tokenizer(\n",
    "    highest_matching_table_column_names, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute the token embeddings for the column names of the highest matching table\n",
    "with torch.no_grad():\n",
    "    highest_matching_table_column_names_output = model(\n",
    "        **highest_matching_table_column_names_encoded)\n",
    "\n",
    "# Perform mean pooling on the output of the language model for the column names of the highest matching table\n",
    "highest_matching_table_column_names_embeddings = mean_pooling(\n",
    "    highest_matching_table_column_names_output, highest_matching_table_column_names_encoded['attention_mask'])\n",
    "\n",
    "# Normalize the embeddings for the column names of the highest matching table\n",
    "highest_matching_table_column_names_embeddings = F.normalize(\n",
    "    highest_matching_table_column_names_embeddings, p=2, dim=1)\n",
    "\n",
    "# Compute the cosine similarity between the query sentence embedding and the column names embeddings of the highest matching table\n",
    "cosine_similarities_highest_matching_table_columns = torch.nn.functional.cosine_similarity(\n",
    "    query_sentence_embedding, highest_matching_table_column_names_embeddings, dim=1)\n",
    "\n",
    "# Find the most similar column name in the highest matching table by sorting the cosine similarities in descending order\n",
    "most_similar_highest_matching_table_column_name_index = cosine_similarities_highest_matching_table_columns.argmax()\n",
    "most_similar_highest_matching_table_column_name = highest_matching_table_column_names[\n",
    "    most_similar_highest_matching_table_column_name_index]\n",
    "\n",
    "\n",
    "# Generate an SQL SELECT query based on the most similar table names and column names\n",
    "query = f\"SELECT {most_similar_highest_matching_table_column_name} FROM {most_similar_table_names[0]}\"\n",
    "\n",
    "# Iterate through the list of possible queries and execute each one\n",
    "\n",
    "# Print the generated SQL query\n",
    "print(query)\n",
    "\n",
    "try:\n",
    "    cursor.execute(query)\n",
    "    results = cursor.fetchall()\n",
    "    print(f'Query: {query}')\n",
    "    print(f'Results: {results}')\n",
    "except Exception as e:\n",
    "    print(f'Error: {e}')\n",
    "\n",
    "\n",
    "# close the connection to the database\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8dfc8609dd5180df3f92c99aa3a5777dcce9aad48aad7f045d6c2f519bdbe44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
