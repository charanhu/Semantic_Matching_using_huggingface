{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NLQ to Dashboard Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd3ORGdiyeQc",
        "outputId": "8a9abd13-e093-4eb4-fce4-3de4ba448c1b"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5mVSDPPBJQA"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"NLQ_to_Dashboard_Demo.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1m8U6lb2iQgrKtUGFL8FKlJ1mHFsde1ZQ\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import sqlite3\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model from HuggingFace Hub\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    'sentence-transformers/all-MiniLM-L6-v2')\n",
        "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Load the model and tokenizer\n",
        "tokenizer_decoder = AutoTokenizer.from_pretrained(\"tscholak/3vnuv1vf\")\n",
        "model_decoder = AutoModelForSeq2SeqLM.from_pretrained(\"tscholak/3vnuv1vf\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function for Meanpooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDzNb6Y1BVgw"
      },
      "outputs": [],
      "source": [
        "# Mean Pooling - Take attention mask into account for correct averaging\n",
        "\n",
        "\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    # First element of model_output contains all token embeddings\n",
        "    token_embeddings = model_output[0]\n",
        "    input_mask_expanded = attention_mask.unsqueeze(\n",
        "        -1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to get Semantic Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj97hfgNB3dg"
      },
      "outputs": [],
      "source": [
        "def encoder_decoder_1(query_sentence, table_names, tokenizer, model, cursor):\n",
        "    # Tokenize query sentence, table names\n",
        "    query_sentence_encoded = tokenizer(\n",
        "        [query_sentence], padding=True, truncation=True, return_tensors='pt')\n",
        "    table_names_encoded = tokenizer(\n",
        "        table_names, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "    # Compute token embeddings for query sentence, table names\n",
        "    with torch.no_grad():\n",
        "        query_sentence_output = model(**query_sentence_encoded)\n",
        "        table_names_output = model(**table_names_encoded)\n",
        "\n",
        "    # Perform pooling for query sentence, table names\n",
        "    query_sentence_embedding = mean_pooling(\n",
        "        query_sentence_output, query_sentence_encoded['attention_mask'])\n",
        "    table_names_embeddings = mean_pooling(\n",
        "        table_names_output, table_names_encoded['attention_mask'])\n",
        "\n",
        "    # Normalize embeddings for query sentence, table names\n",
        "    query_sentence_embedding = F.normalize(\n",
        "        query_sentence_embedding, p=2, dim=1)\n",
        "    table_names_embeddings = F.normalize(table_names_embeddings, p=2, dim=1)\n",
        "\n",
        "    # Find the most similar table names by computing the cosine similarity between the query sentence embedding and the table names embeddings\n",
        "    cosine_similarities_tables = torch.nn.functional.cosine_similarity(\n",
        "        query_sentence_embedding, table_names_embeddings, dim=1)\n",
        "    most_similar_table_names_indices = cosine_similarities_tables.argsort(\n",
        "        descending=True)\n",
        "    most_similar_table_names = [table_names[i]\n",
        "                                for i in most_similar_table_names_indices]\n",
        "\n",
        "    # Find the index of the highest matching table name by finding the maximum value in the list of cosine similarities for the table names\n",
        "    max_similarity_table_index = cosine_similarities_tables.argmax()\n",
        "\n",
        "    # Get the highest matching table name by using the index obtained above\n",
        "    highest_matching_table_name = table_names[max_similarity_table_index]\n",
        "\n",
        "    # Find the column names of the highest matching table by querying the database\n",
        "    cursor.execute(f\"PRAGMA table_info({highest_matching_table_name});\")\n",
        "    highest_matching_table_column_names = [\n",
        "        column_info[1] for column_info in cursor.fetchall()]\n",
        "\n",
        "    highest_matching_table_column_names = \", \".join(\n",
        "        highest_matching_table_column_names)\n",
        "\n",
        "    highest_matching_table_column_names = list(\n",
        "        highest_matching_table_column_names.split(\", \"))\n",
        "\n",
        "    highest_matching_table_column_names = [column_name.replace(\n",
        "        ' ', '_') for column_name in highest_matching_table_column_names]\n",
        "\n",
        "    return highest_matching_table_name, highest_matching_table_column_names\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to Generate SQL Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zd3s5Ct1B6Yu"
      },
      "outputs": [],
      "source": [
        "def encoder_decoder_2(query_sentence, database_name, highest_matching_table_name, highest_matching_table_column_names, tokenizer_decoder, model_decoder):\n",
        "    # Make input text in this format. input_text = \"list names of film released in 2018 and rating more than 6? | IMDB | Movie: rating, year, title\"\n",
        "    input_text_1 = query_sentence + \" | \" + database_name + \" | \" + \\\n",
        "        highest_matching_table_name + \": \" + \\\n",
        "        str(highest_matching_table_column_names)\n",
        "\n",
        "    input_ids_1 = tokenizer_decoder.encode(input_text_1, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate the output\n",
        "    output_1 = model_decoder.generate(\n",
        "        input_ids_1, max_length=128, num_beams=4, early_stopping=True)\n",
        "\n",
        "    # Decode the output\n",
        "    output_text_1 = tokenizer_decoder.decode(\n",
        "        output_1[0], skip_special_tokens=True)\n",
        "    # Output: IMDB | select title from movie where rating > 6 and year = 2018\n",
        "\n",
        "    # split the output into two parts (sql and table name)\n",
        "    output_text_1 = output_text_1.split(\"|\")\n",
        "    sql_query = output_text_1[1].strip()\n",
        "\n",
        "    # return the sql query\n",
        "    return sql_query\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to Execute SQL Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8sIqMMdB9II"
      },
      "outputs": [],
      "source": [
        "def sql_executor(sql_query, highest_matching_table_column_names, cursor):\n",
        "    # # replace column names spaces with underscores\n",
        "    # highest_matching_table_column_names = [column_name.replace(\n",
        "    #     ' ', '_') for column_name in highest_matching_table_column_names]\n",
        "\n",
        "    # convert list to lower case\n",
        "    highest_matching_table_column_names = [\n",
        "        x.lower() for x in highest_matching_table_column_names]\n",
        "\n",
        "    # if s3 contains any of the words in lst1 then replace it with double quotes\n",
        "    for i in highest_matching_table_column_names:\n",
        "        if i in sql_query:\n",
        "            sql_query = sql_query.replace(i, '\"'+i+'\"')\n",
        "\n",
        "    # replace underscore with space\n",
        "    sql_query = sql_query.replace(\"_\", \" \")\n",
        "    # replace all single quotes with double quotes\n",
        "    sql_query = sql_query.replace(\"'\", '\"')\n",
        "    # Print the sql query\n",
        "    print(sql_query)\n",
        "    print(\" \")\n",
        "\n",
        "    # Execute the sql\n",
        "    cursor.execute(sql_query)\n",
        "    result = cursor.fetchall()\n",
        "\n",
        "    # print the result\n",
        "    print(result)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CAb_Dd-9mdP",
        "outputId": "e1fe51b0-2e6c-4782-a4ad-927742b84c7a"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    # call above functions\n",
        "    # import data\n",
        "    # Query sentence\n",
        "    query_sentence = input(\"Enter question: \")\n",
        "\n",
        "    # Connect to database and fetch table names and column names\n",
        "    conn = sqlite3.connect('/content/data.sqlite')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Get the filename that is connected above\n",
        "    filename = conn.cursor().execute(\"PRAGMA database_list;\").fetchall()[0][2]\n",
        "\n",
        "    # filename = '/content/Db-IMDB.db'\n",
        "    # split the filename to get the database name\n",
        "    database_name = filename.split('/')[-1].split('.')[0]\n",
        "\n",
        "    table_names = [table_info[0] for table_info in cursor.execute(\n",
        "        \"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()]\n",
        "    column_names = []\n",
        "    for table_name in table_names:\n",
        "        cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
        "        column_names.extend([column_info[1]\n",
        "                            for column_info in cursor.fetchall()])\n",
        "\n",
        "    highest_matching_table_name, highest_matching_table_column_names = encoder_decoder_1(\n",
        "        query_sentence, table_names, tokenizer, model, cursor)\n",
        "\n",
        "    sql_query = encoder_decoder_2(query_sentence, database_name, highest_matching_table_name,\n",
        "                                  highest_matching_table_column_names, tokenizer_decoder, model_decoder)\n",
        "\n",
        "    sql_executor(sql_query, highest_matching_table_column_names, cursor)\n",
        "\n",
        "    # Close database connection\n",
        "    conn.close()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test with Natural Language Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQSoKHDt-S6h"
      },
      "outputs": [],
      "source": [
        "list the sales, ship mode of south, west region where sales in greter than 100 and city is California\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "c1f682f24181e02bec5294285fb1c175cb07785bd2390f987c80770a76d37385"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
